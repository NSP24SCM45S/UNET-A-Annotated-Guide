# -*- coding: utf-8 -*-
"""DL Project 3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_81T4AUBstRuL-q6FNeQkZjHuRFK4UAO

# Carvana Database
"""

import os
from PIL import Image
from torch.utils.data import Dataset
from torchvision import transforms

class CarvanaDataset(Dataset):
    def __init__(self, root_dir, is_test=False):
        """
        Initialize the Carvana dataset by setting up image and mask file paths.

        Args:
            root_dir (str): The root directory containing the dataset folders.
            is_test (bool, optional): If True, use test dataset folders; otherwise, use training dataset. Defaults to False.
        """
        self.root_dir = root_dir

        # Determine the image and mask directories based on the dataset type
        if is_test:
            image_dir = os.path.join(root_dir, 'manual_test')
            mask_dir = os.path.join(root_dir, 'manual_test_masks')
        else:
            image_dir = os.path.join(root_dir, 'train')
            mask_dir = os.path.join(root_dir, 'train_masks')

        # Get sorted lists of all image and mask file paths
        self.image_paths = sorted([
            os.path.join(image_dir, fname) for fname in os.listdir(image_dir)
        ])
        self.mask_paths = sorted([
            os.path.join(mask_dir, fname) for fname in os.listdir(mask_dir)
        ])

        # Define transformations to apply to images and masks
        self.transform = transforms.Compose([
            transforms.Resize((512, 512)),  # Resize to 512x512 pixels
            transforms.ToTensor()           # Convert to PyTorch tensors
        ])

    def __getitem__(self, index):
        """
        Retrieve an image and its corresponding mask at the specified index.

        Args:
            index (int): The index of the item to retrieve.

        Returns:
            tuple: A tuple containing the transformed image and mask tensors.
        """
        # Load and convert the image to RGB format
        image = Image.open(self.image_paths[index]).convert('RGB')
        # Load and convert the mask to grayscale (single channel)
        mask = Image.open(self.mask_paths[index]).convert('L')

        # Apply the transformations to both image and mask
        image = self.transform(image)
        mask = self.transform(mask)

        return image, mask

    def __len__(self):
        """
        Get the total number of items in the dataset.

        Returns:
            int: The number of image-mask pairs.
        """
        return len(self.image_paths)

import torch
import torch.nn as nn

class DoubleConv(nn.Module):
    def __init__(self, in_channels, out_channels):
        """
        A module that performs two consecutive convolutional layers,
        each followed by a ReLU activation function.

        Args:
            in_channels (int): Number of input feature channels.
            out_channels (int): Number of output feature channels.
        """
        super(DoubleConv, self).__init__()
        # Define the sequence of layers for the double convolution
        self.layers = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),  # Activation function
            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),
            nn.ReLU(inplace=True)   # Activation function
        )

    def forward(self, x):
        """
        Forward pass that applies the double convolution to the input tensor.

        Args:
            x (torch.Tensor): Input tensor.

        Returns:
            torch.Tensor: Output tensor after convolution and activation.
        """
        return self.layers(x)


class DownSample(nn.Module):
    def __init__(self, in_channels, out_channels):
        """
        A downsampling module that applies double convolution followed by max pooling.

        Args:
            in_channels (int): Number of input feature channels.
            out_channels (int): Number of output feature channels.
        """
        super(DownSample, self).__init__()
        # Initialize the double convolution layer
        self.double_conv = DoubleConv(in_channels, out_channels)
        # Define the max pooling layer for downsampling
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)

    def forward(self, x):
        """
        Forward pass that applies double convolution and max pooling.

        Args:
            x (torch.Tensor): Input tensor.

        Returns:
            tuple: A tuple containing the features before pooling and after pooling.
        """
        features = self.double_conv(x)
        pooled = self.pool(features)
        return features, pooled


class UpSample(nn.Module):
    def __init__(self, in_channels, out_channels):
        """
        An upsampling module that performs transpose convolution and feature concatenation.

        Args:
            in_channels (int): Number of input feature channels.
            out_channels (int): Number of output feature channels.
        """
        super(UpSample, self).__init__()
        # Define the transpose convolution layer for upsampling
        self.upconv = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)
        # Initialize the double convolution layer
        self.double_conv = DoubleConv(in_channels, out_channels)

    def forward(self, x1, x2):
        """
        Forward pass that upsamples and concatenates features from the encoder and decoder paths.

        Args:
            x1 (torch.Tensor): Input tensor from the previous layer in the decoder.
            x2 (torch.Tensor): Corresponding tensor from the encoder for skip connection.

        Returns:
            torch.Tensor: Output tensor after upsampling and double convolution.
        """
        x1 = self.upconv(x1)
        # Concatenate along the channel dimension
        x = torch.cat([x1, x2], dim=1)
        return self.double_conv(x)

"""# unet"""

import torch
import torch.nn as nn

class UNet(nn.Module):
    def __init__(self, in_channels, num_classes):
        """
        U-Net architecture for image segmentation tasks.

        Args:
            in_channels (int): Number of input channels (e.g., 3 for RGB images).
            num_classes (int): Number of output classes for segmentation.
        """
        super(UNet, self).__init__()

        # Encoder path (downsampling)
        self.down1 = DownSample(in_channels, 64)
        self.down2 = DownSample(64, 128)
        self.down3 = DownSample(128, 256)
        self.down4 = DownSample(256, 512)

        # Bottleneck layer
        self.bottleneck = DoubleConv(512, 1024)

        # Decoder path (upsampling)
        self.up1 = UpSample(1024, 512)
        self.up2 = UpSample(512, 256)
        self.up3 = UpSample(256, 128)
        self.up4 = UpSample(128, 64)

        # Final convolution layer to produce the desired number of output channels
        self.final_conv = nn.Conv2d(64, num_classes, kernel_size=1)

    def forward(self, x):
        """
        Defines the forward pass through the network.

        Args:
            x (torch.Tensor): Input tensor.

        Returns:
            torch.Tensor: Output tensor with segmentation maps.
        """
        # Apply downsampling and collect features for skip connections
        features1, x1 = self.down1(x)
        features2, x2 = self.down2(x1)
        features3, x3 = self.down3(x2)
        features4, x4 = self.down4(x3)

        # Bottleneck
        x = self.bottleneck(x4)

        # Apply upsampling while concatenating with corresponding encoder features
        x = self.up1(x, features4)
        x = self.up2(x, features3)
        x = self.up3(x, features2)
        x = self.up4(x, features1)

        # Final output layer
        output = self.final_conv(x)
        return output

"""# mini unet"""

class MiniUNet(nn.Module):
    def __init__(self, in_channels=3, num_classes=1):
        super(MiniUNet, self).__init__()
        self.encoder = nn.Sequential(
            nn.Conv2d(in_channels, 16, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2)
        )
        self.bottleneck = nn.Sequential(
            nn.Conv2d(16, 32, kernel_size=3, padding=1),
            nn.ReLU()
        )
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(32, 16, kernel_size=2, stride=2),
            nn.ReLU(),
            nn.Conv2d(16, num_classes, kernel_size=1)
        )

    def forward(self, x):
        x = self.encoder(x)
        x = self.bottleneck(x)
        x = self.decoder(x)
        return x

from google.colab import drive
drive.mount('/content/drive')

#unzip
!unzip -q train.zip

!unzip -q train_masks.zip

"""# mini unet output"""

import torch.optim as optim
from tqdm import tqdm

def compute_metrics(pred, target):
    pred = pred > 0.5  # Binary threshold
    target = target > 0.5
    intersection = (pred & target).sum().float()
    union = (pred | target).sum().float()
    iou = intersection / (union + 1e-6)
    dice = 2 * intersection / (pred.sum() + target.sum() + 1e-6)
    return iou.item(), dice.item()

device = torch.device("cpu")  # For CPU-only compatibility
model = MiniUNet().to(device)
criterion = nn.BCEWithLogitsLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

num_epochs = 5
for epoch in range(num_epochs):
    model.train()
    train_loss = 0.0

    for images, masks in tqdm(train_loader, desc=f"Epoch {epoch+1}/{num_epochs}"):
        images, masks = images.to(device), masks.to(device)
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, masks)
        loss.backward()
        optimizer.step()
        train_loss += loss.item()

    print(f"Epoch {epoch+1} Training Loss: {train_loss/len(train_loader):.4f}")

    # Validation
    model.eval()
    val_loss = 0.0
    iou_scores, dice_scores = [], []
    with torch.no_grad():
        for images, masks in val_loader:
            images, masks = images.to(device), masks.to(device)
            outputs = model(images)
            loss = criterion(outputs, masks)
            val_loss += loss.item()

            pred_masks = torch.sigmoid(outputs)
            iou, dice = compute_metrics(pred_masks, masks)
            iou_scores.append(iou)
            dice_scores.append(dice)

    print(f"Epoch {epoch+1} Validation Loss: {val_loss/len(val_loader):.4f}")
    print(f"Validation IoU: {np.mean(iou_scores):.4f}, Dice Coefficient: {np.mean(dice_scores):.4f}")

"""# mini unet eval"""

import matplotlib.pyplot as plt

def visualize_results(model, dataloader, device):
    model.eval()
    images, masks = next(iter(dataloader))
    images, masks = images.to(device), masks.to(device)

    with torch.no_grad():
        preds = torch.sigmoid(model(images))

    # Plot the results
    fig, axes = plt.subplots(3, len(images), figsize=(15, 5))
    for i in range(len(images)):
        axes[0, i].imshow(images[i].permute(1, 2, 0).cpu())
        axes[0, i].set_title("Input Image")
        axes[0, i].axis("off")

        axes[1, i].imshow(masks[i].squeeze().cpu(), cmap='gray')
        axes[1, i].set_title("Ground Truth")
        axes[1, i].axis("off")

        axes[2, i].imshow(preds[i].squeeze().cpu(), cmap='gray')
        axes[2, i].set_title("Predicted Mask")
        axes[2, i].axis("off")

    plt.tight_layout()
    plt.show()

visualize_results(model, val_loader, device)

"""# unet training"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, random_split
from tqdm import tqdm

# Assuming CarvanaDataset and UNet classes are defined as per previous code snippets
val_loss = []
train_loss = []

if __name__ == "__main__":
    # Hyperparameters and file paths
    LEARNING_RATE = 3e-4
    BATCH_SIZE = 32
    NUM_EPOCHS = 5
    DATA_PATH = "/content"  # Path to the dataset
    MODEL_SAVE_PATH = "/content/drive/MyDrive/DL_Project/unet2.pth"  # Where to save the trained model

    # Set the computation device to GPU if available; otherwise, use CPU
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # Initialize the dataset
    dataset = CarvanaDataset(root_dir=DATA_PATH)

    # Split the dataset into training and validation sets
    generator = torch.Generator().manual_seed(42)  # For reproducibility
    train_size = int(0.8 * len(dataset))
    val_size = len(dataset) - train_size
    train_dataset, val_dataset = random_split(dataset, [train_size, val_size], generator=generator)

    # Create data loaders for training and validation
    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)

    # Initialize the model, loss function, and optimizer
    model = UNet(in_channels=3, num_classes=1).to(device)
    criterion = nn.BCEWithLogitsLoss()  # Suitable for binary segmentation tasks
    optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)

    # Training loop
    for epoch in range(NUM_EPOCHS):
        model.train()  # Set model to training mode
        running_loss = 0.0

        # Iterate over the training data
        for images, masks in tqdm(train_loader, desc=f"Epoch {epoch+1}/{NUM_EPOCHS} - Training"):
            # Move data to the computation device and ensure correct data type
            images = images.to(device, dtype=torch.float32)
            masks = masks.to(device, dtype=torch.float32)

            # Forward pass: compute model predictions
            outputs = model(images)
            loss = criterion(outputs, masks)

            # Backward pass and optimization step
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            # Accumulate loss for averaging
            running_loss += loss.item()

        # Calculate average training loss for the epoch
        avg_train_loss = running_loss / len(train_loader)

        # Validation loop
        model.eval()  # Set model to evaluation mode
        val_loss = 0.0

        with torch.no_grad():  # Disable gradient calculation for validation
            for images, masks in tqdm(val_loader, desc=f"Epoch {epoch+1}/{NUM_EPOCHS} - Validation"):
                images = images.to(device, dtype=torch.float32)
                masks = masks.to(device, dtype=torch.float32)

                # Forward pass: compute model predictions
                outputs = model(images)
                loss = criterion(outputs, masks)

                # Accumulate loss for averaging
                val_loss += loss.item()

        # Calculate average validation loss for the epoch
        avg_val_loss = val_loss / len(val_loader)

        # Print training and validation loss
        print(f"Epoch [{epoch+1}/{NUM_EPOCHS}] - Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}")

      val_loss.append(avg_val_loss)
      train_loss.append(avg_train_loss)

    # Save the trained model's state
    torch.save(model.state_dict(), MODEL_SAVE_PATH)

import torch
import torch.nn as nn
from torchvision import transforms
from PIL import Image
import matplotlib.pyplot as plt

# Ensure that UNet and any necessary classes are defined or imported before using this script

def single_image_inference(image_path, model_path, device):
    """
    Perform inference on a single image using a trained U-Net model to generate a segmentation mask.

    Args:
        image_path (str): The file path to the input image.
        model_path (str): The file path to the saved model weights.
        device (torch.device): The device to run the inference on (CPU or GPU).
    """
    # Load the trained U-Net model and move it to the specified device
    model = UNet(in_channels=3, num_classes=1).to(device)
    model.load_state_dict(torch.load(model_path, map_location=device, weights_only=True))
    model.eval()  # Set the model to evaluation mode

    # Define the transformations to apply to the input image
    transform = transforms.Compose([
        transforms.Resize((512, 512)),  # Resize the image to match the model's input size
        transforms.ToTensor()           # Convert the image to a PyTorch tensor
    ])

    # Load and preprocess the image
    image = Image.open(image_path).convert('RGB')  # Ensure the image is in RGB format
    input_tensor = transform(image).unsqueeze(0).to(device)  # Add batch dimension and move to device

    # Perform inference without calculating gradients
    with torch.no_grad():
        output = model(input_tensor)

    # Apply a sigmoid activation and threshold to obtain a binary mask
    pred_mask = torch.sigmoid(output).squeeze(0).cpu()
    pred_mask = (pred_mask > 0.5).float()

    # Convert tensors to NumPy arrays for visualization
    image_np = input_tensor.squeeze(0).cpu().permute(1, 2, 0).numpy()
    mask_np = pred_mask.squeeze(0).numpy()

    # Plot the original image and the predicted mask side by side
    fig, axes = plt.subplots(1, 2, figsize=(12, 6))
    axes[0].imshow(image_np)
    axes[0].set_title("Input Image")
    axes[0].axis("off")

    axes[1].imshow(mask_np, cmap='gray')
    axes[1].set_title("Predicted Mask")
    axes[1].axis("off")

    plt.show()

if __name__ == "__main__":
    # Define the paths to the image and the trained model
    IMAGE_PATH = "/content/drive/MyDrive/DL_Project/11.jpg"
    MODEL_PATH = "/content/drive/MyDrive/DL_Project/unet2.pth"

    # Set the device to GPU if available, else CPU
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # Run inference on a single image
    single_image_inference(IMAGE_PATH, MODEL_PATH, device)

import matplotlib.pyplot as plt
import torch
from torchvision import transforms
from PIL import Image

def visualize_inference(image_path, mask_path, model_path, device):
    """
    Display input image, ground truth mask, and predicted mask side-by-side.

    Args:
        image_path (str): Path to the input image.
        mask_path (str): Path to the ground truth mask.
        model_path (str): Path to the trained model.
        device (str): Device for computation ('cuda' or 'cpu').
    """
    # Load the model
    model = UNet(in_channels=3, num_classes=1).to(device)
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.eval()

    # Define transformation for image
    transform = transforms.Compose([
        transforms.Resize((512, 512)),
        transforms.ToTensor()
    ])

    # Load and preprocess the input image and ground truth mask
    image = transform(Image.open(image_path)).unsqueeze(0).to(device)
    true_mask = transform(Image.open(mask_path)).squeeze(0).cpu()

    # Perform inference
    with torch.no_grad():
        pred_mask = model(image).squeeze(0).cpu()

    # Binarize the predicted mask
    pred_mask = (pred_mask > 0).float().squeeze()

    # Visualize the input image, true mask, and predicted mask
    fig, axs = plt.subplots(1, 3, figsize=(15, 5))
    axs[0].imshow(image.squeeze(0).permute(1, 2, 0).cpu())
    axs[0].set_title("Input Image")
    axs[0].axis("off")

    axs[1].imshow(true_mask, cmap="gray")
    axs[1].set_title("Ground Truth Mask")
    axs[1].axis("off")

    axs[2].imshow(pred_mask, cmap="gray")
    axs[2].set_title("Predicted Mask")
    axs[2].axis("off")

    plt.show()

# Example usage
SINGLE_IMG_PATH = "/content/train/03a857ce842d_01.jpg"
MASK_PATH = "/content/train_masks/03a857ce842d_01_mask.gif"
MODEL_PATH = "/content/drive/MyDrive/DL_Project/unet2.pth"
device = "cuda" if torch.cuda.is_available() else "cpu"
visualize_inference(SINGLE_IMG_PATH, MASK_PATH, MODEL_PATH, device)

import torch
import numpy as np

def compute_metrics(pred, target):
    """
    Compute IoU and Dice Coefficient for segmentation.

    Args:
        pred (torch.Tensor): Predicted binary mask.
        target (torch.Tensor): Ground truth binary mask.

    Returns:
        dict: IoU and Dice metrics.
    """
    pred = pred > 0.5  # Threshold predictions
    target = target > 0.5  # Threshold ground truth

    intersection = (pred & target).float().sum((1, 2))  # Element-wise AND
    union = (pred | target).float().sum((1, 2))        # Element-wise OR
    dice = (2 * intersection) / (pred.sum((1, 2)) + target.sum((1, 2)))

    iou = intersection / (union + 1e-6)
    dice = dice.mean().item()  # Convert to scalar
    iou = iou.mean().item()    # Convert to scalar

    return {'IoU': iou, 'Dice': dice}

def analyze_results(model, dataloader, device):
    """
    Analyze segmentation results and compute metrics.

    Args:
        model (nn.Module): Trained segmentation model.
        dataloader (DataLoader): DataLoader for evaluation data.
        device (torch.device): Device to perform computations.

    Returns:
        dict: Average IoU and Dice metrics.
    """
    model.eval()
    iou_scores = []
    dice_scores = []

    with torch.no_grad():
        for images, masks in dataloader:
            images = images.to(device)
            masks = masks.to(device)

            # Perform inference
            outputs = torch.sigmoid(model(images))  # Apply sigmoid activation
            metrics = compute_metrics(outputs, masks)

            iou_scores.append(metrics['IoU'])
            dice_scores.append(metrics['Dice'])

    avg_iou = np.mean(iou_scores)
    avg_dice = np.mean(dice_scores)
    print(f"Average IoU: {avg_iou:.4f}")
    print(f"Average Dice Coefficient: {avg_dice:.4f}")

    return {'IoU': avg_iou, 'Dice': avg_dice}

from torch.utils.data import DataLoader, random_split

if __name__ == "__main__":
    # Define paths
    DATA_PATH = "/content"
    MODEL_PATH = "/content/drive/MyDrive/DL_Project/unet2.pth"

    # Hyperparameters
    BATCH_SIZE = 16
    NUM_CLASSES = 1

    # Initialize dataset
    dataset = CarvanaDataset(root_dir=DATA_PATH)
    train_size = int(0.8 * len(dataset))
    val_size = len(dataset) - train_size
    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])

    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)

    # Load trained model
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = UNet(in_channels=3, num_classes=NUM_CLASSES).to(device)
    model.load_state_dict(torch.load(MODEL_PATH, weights_only=True))

    # Analyze results
    metrics = analyze_results(model, val_loader, device)


    IoU, Dice = metrics['IoU'], metrics['Dice']

import matplotlib.pyplot as plt

def plot_training_history(train_losses, val_losses):
    """
    Plot training and validation loss over epochs.

    Args:
        train_losses (list): List of training losses for each epoch.
        val_losses (list): List of validation losses for each epoch.
    """
    epochs = range(1, len(train_losses) + 1)

    plt.figure(figsize=(10, 5))
    plt.plot(epochs, train_losses, label="Training Loss")
    plt.plot(epochs, val_losses, label="Validation Loss")
    plt.xlabel("Epochs")
    plt.ylabel("Loss")
    plt.title("Training and Validation Loss over Epochs")
    plt.legend()
    plt.show()

# Example usage with placeholder data
train_losses = train_loss  # Replace with actual values
val_losses = val_loss    # Replace with actual values
plot_training_history(train_losses, val_losses)

def plot_metric_over_epochs(metric_values, metric_name="Accuracy"):
    """
    Plot a metric (e.g., accuracy or IOU) over epochs.

    Args:
        metric_values (list): List of metric values for each epoch.
        metric_name (str): Name of the metric to display on the plot.
    """
    epochs = range(1, len(metric_values) + 1)

    plt.figure(figsize=(10, 5))
    plt.plot(epochs, metric_values, label=metric_name)
    plt.xlabel("Epochs")
    plt.ylabel(metric_name)
    plt.title(f"{metric_name} over Epochs")
    plt.legend()
    plt.show()

# Example usage with placeholder data
iou_values = IoU  # Replace with actual values
plot_metric_over_epochs(iou_values, metric_name="IOU")

def visualize_results(image_path, true_mask_path, predicted_mask):
    """
    Display input image, ground truth mask, and predicted mask.

    Args:
        image_path (str): Path to the input image.
        true_mask_path (str): Path to the ground truth mask.
        predicted_mask (tensor): Predicted mask from the model.
    """
    # Load the input image and ground truth mask
    image = Image.open(image_path)
    true_mask = Image.open(true_mask_path)

    # Convert predicted mask to binary
    predicted_mask = (predicted_mask > 0.5).float().cpu()

    # Display results
    fig, axs = plt.subplots(1, 3, figsize=(15, 5))
    axs[0].imshow(image)
    axs[0].set_title("Input Image")
    axs[0].axis("off")

    axs[1].imshow(true_mask, cmap="gray")
    axs[1].set_title("Ground Truth Mask")
    axs[1].axis("off")

    axs[2].imshow(predicted_mask, cmap="gray")
    axs[2].set_title("Predicted Mask")
    axs[2].axis("off")

    plt.show()

import os
from PIL import Image
import matplotlib.pyplot as plt

def overview_dataset_structure(dataset_path):
    """
    Overview of the Carvana Image Masking Challenge dataset structure.

    Args:
        dataset_path (str): Path to the dataset directory.
    """
    # Define the paths for images and masks
    train_image_path = os.path.join(dataset_path, "train")
    train_mask_path = os.path.join(dataset_path, "train_masks")
    test_image_path = os.path.join(dataset_path, "manual_test")
    test_mask_path = os.path.join(dataset_path, "manual_test_masks")

    print("Dataset Overview:")
    print(f"Training Images: {len(os.listdir(train_image_path))} high-resolution images")
    print(f"Training Masks: {len(os.listdir(train_mask_path))} annotated masks")
    print(f"Test Images: {len(os.listdir(test_image_path))} high-resolution images")
    print(f"Test Masks: {len(os.listdir(test_mask_path))} annotated masks")

    # Display sample images and corresponding masks
    sample_image = os.listdir(train_image_path)[0]
    sample_mask = os.listdir(train_mask_path)[0]

    img = Image.open(os.path.join(train_image_path, sample_image))
    mask = Image.open(os.path.join(train_mask_path, sample_mask))

    plt.figure(figsize=(10, 5))
    plt.subplot(1, 2, 1)
    plt.imshow(img)
    plt.title("Sample Image")
    plt.axis("off")

    plt.subplot(1, 2, 2)
    plt.imshow(mask, cmap="gray")
    plt.title("Sample Mask")
    plt.axis("off")
    plt.show()

# Example usage
DATASET_PATH = "/content"
overview_dataset_structure(DATASET_PATH)

import numpy as np
import torch

def calculate_iou(predicted_mask, true_mask):
    """
    Calculate Intersection Over Union (IOU) for a predicted mask and ground truth mask.

    Args:
        predicted_mask (torch.Tensor): Predicted mask (binary tensor).
        true_mask (torch.Tensor): Ground truth mask (binary tensor).

    Returns:
        float: IOU score.
    """
    predicted_mask = predicted_mask > 0.5  # Binarize predictions
    true_mask = true_mask > 0.5  # Binarize ground truth

    intersection = torch.sum(predicted_mask & true_mask).item()
    union = torch.sum(predicted_mask | true_mask).item()

    return intersection / union if union > 0 else 0

# Example usage (assumes `model`, `test_loader` are already defined)
model.eval()
ious = []
with torch.no_grad():
    for images, masks in test_loader:  # Replace `test_loader` with your test dataloader
        images = images.to(device)
        masks = masks.to(device)

        predictions = model(images)
        predictions = torch.sigmoid(predictions)  # Apply sigmoid for binary classification

        for pred, mask in zip(predictions, masks):
            iou_score = calculate_iou(pred, mask)
            ious.append(iou_score)

print(f"Average IOU on test set: {np.mean(ious):.4f}")

def visualize_segmentation_results(image, true_mask, predicted_mask):
    """
    Visualize segmentation results for an image with true and predicted masks.

    Args:
        image (torch.Tensor): Input image.
        true_mask (torch.Tensor): Ground truth mask.
        predicted_mask (torch.Tensor): Predicted mask.
    """
    # Move tensors to CPU and detach
    image = image.permute(1, 2, 0).cpu().numpy()
    true_mask = true_mask.squeeze().cpu().numpy()
    predicted_mask = (predicted_mask.squeeze() > 0.5).cpu().numpy()

    # Plot the results
    plt.figure(figsize=(15, 5))
    plt.subplot(1, 3, 1)
    plt.imshow(image)
    plt.title("Input Image")
    plt.axis("off")

    plt.subplot(1, 3, 2)
    plt.imshow(true_mask, cmap="gray")
    plt.title("Ground Truth Mask")
    plt.axis("off")

    plt.subplot(1, 3, 3)
    plt.imshow(predicted_mask, cmap="gray")
    plt.title("Predicted Mask")
    plt.axis("off")
    plt.show()

# Example usage (visualize first batch)
with torch.no_grad():
    for images, masks in test_loader:  # Replace `test_loader` with your test dataloader
        predictions = model(images.to(device))
        predictions = torch.sigmoid(predictions)  # Apply sigmoid activation
        for i in range(min(len(images), 3)):  # Visualize up to 3 samples
            visualize_segmentation_results(images[i], masks[i], predictions[i])
        break